---
title: "Zadatak1a"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Zadatak 1: a) Analizirati set podataka i izvršiti sljedeće: - Odrediti
tipove i distribuciju atributa; - Ispuniti nedostajuće i ukloniti
nepodobne vrijednosti ukoliko je potrebno; - Uraditi transformaciju i
skaliranje atributa u skladu sa njihovom distribucijom i algoritmima
koji će se koristiti u narednim koracima; - Odrediti da li set podataka
ima klastering tendenciju; - Utvrditi da li je potrebno izvršiti dodatne
analize za podatke, kao i dodatne transformacije, skaliranja i sl.

```{r}
podaci <- read.csv("marketing_campaign.csv", fileEncoding = 'UTF-8', sep = '\t')
dim(podaci)
names(podaci)
```

```{r}
summary(podaci)
```

```{r}
#- Odrediti tipove i distribuciju atributa;

#crtanje barcharta
for (i in colnames(podaci)){
  #if (class(podaci[[i]]) == "character")
    barplot(table(podaci[[i]]),
    main=colnames(podaci[i]),
    ylim= c(0, length(podaci[[i]])),
    ylab="Broj",
    border="red",
    col="blue",
    density=10
    )
  #else if (class(podaci[[i]]) == "integer")
  #  boxplot(table(podaci[[i]]), main = colnames(podaci[i]))
}
unique(podaci$Marital_Status)
unique(podaci$Education)
#dopuniti
```

```{r}
#iz rezultata funkcije summary možemo zaključiti da se jedino u atributu Income nalaze NA vrijednosti, pa ćemo ih popuniti medijanom
podaci$Income[is.na(podaci$Income)]=median(podaci$Income,na.rm=T)
sum(is.na(podaci$Income))
```

Analiza distribucije atributa

```{r}

```

```{r}
#broj unikatnih vrijednosti u kolonama
sapply(podaci, function(x) length(unique(x)))
```

```{r}
# s obzirom da atributi Z_Revenue i Z_CostContact imaju po samo jednu vrijednost, ove kolone su bespotrebne i mogu se odbaciti
podaci = subset(podaci, select=-c(Z_CostContact,Z_Revenue))
```

```{r}
#može nam biti korisan atribut koji opisuje broj godina kupca
trenutna_godina = Sys.Date()
trenutna_godina = format(trenutna_godina,format="%Y")
trenutna_godina = as.integer(trenutna_godina)
podaci$Age = c(trenutna_godina - podaci$Year_Birth)
Sys.Date()
```

```{r}
print(subset(podaci, (Age > 100 | Income > 600000)))
#izbacivanje outliera
podaci <- podaci[!rownames(podaci) %in% c("193", "240", "340", "2234"), ]
```

```{r}
#atribut koji opisuje datum nije loše transformirati u numerički atribut koji opisuje koliko je dana prošlo od prve interakcije korisnika sa kompanijom

podaci$Dt_CustomerCovert1 = as.Date(podaci$Dt_Customer, format = "%d-%m-%Y")
podaci$Dt_CustomerCovert2 = as.Date("15-01-2022", format = "%d-%m-%Y") - as.Date(podaci$Dt_CustomerCovert1, format = "%d-%m-%Y")
podaci$NumberofDayEnrolled = as.numeric(podaci$Dt_CustomerCovert2, units="days")

```

```{r}

#mogu se i spojiti kolone KidHome i TeenHome

podaci$Kidhome = podaci$Kidhome + podaci$Teenhome
podaci$TotalSpent = podaci$MntMeatProducts+podaci$MntFishProducts+podaci$MntWines+podaci$MntFruits+podaci$MntSweetProducts+podaci$MntGoldProds
podaci$Accepted = podaci$AcceptedCmp1+podaci$AcceptedCmp2+podaci$AcceptedCmp3+podaci$AcceptedCmp4+podaci$AcceptedCmp5
```

```{r}
#fviz_nbclust(podaci,kmeans,method="wss")+geom_vline(xintercept=3,linetype=2)
```

```{r}
# #normalizacija
# library(dplyr)
# max <- max(podaci$Income)
# min <- min(podaci$Income)
# podaci <- mutate(podaci, Income = (Income - min) / (max -
# min))
# 
# max <- max(podaci$TotalSpent)
# min <- min(podaci$TotalSpent)
# podaci <- mutate(podaci, TotalSpent = (TotalSpent - min) / (max -
# min))
# max <- max(podaci$NumberofDayEnrolled)
# min <- min(podaci$NumberofDayEnrolled)
# podaci <- mutate(podaci, NumberofDayEnrolled = (NumberofDayEnrolled - min) / (max -
# min))
```

```{r}

#obrisat cemo nepotrebne kolone
drop <- c("Dt_CustomerCovert1","Dt_CustomerCovert2","Dt_Customer", "Year_Birth", "ID", "Teenhome", "MntMeatProducts", "MntFishProducts", "MntWines", "MntFruits", "MntSweetProducts", "MntGoldProds", "AcceptedCmp1", "AcceptedCmp2", "AcceptedCmp3", "AcceptedCmp4", "AcceptedCmp5")
podaci = podaci[,!(names(podaci) %in% drop)]
```

Uraditi transformaciju i skaliranje atributa u skladu sa njihovom
distribucijom i algoritmima koji će se koristiti u narednim koracima;

```{r}
#transformacija atributa
podaci$Education <- as.numeric(factor(podaci$Education))
podaci$Marital_Status <- as.numeric(factor(podaci$Marital_Status))
podaci$Kidhome <- as.numeric(factor(podaci$Kidhome))
podaci$Recency <- as.numeric(factor(podaci$Recency))
podaci$NumDealsPurchases <- as.numeric(factor(podaci$NumDealsPurchases))
podaci$NumWebPurchases <- as.numeric(factor(podaci$NumWebPurchases))
podaci$NumCatalogPurchases <- as.numeric(factor(podaci$NumCatalogPurchases))
podaci$NumStorePurchases <- as.numeric(factor(podaci$NumStorePurchases))
podaci$NumWebVisitsMonth <- as.numeric(factor(podaci$NumWebVisitsMonth))
podaci$Complain <- as.numeric(factor(podaci$Complain))
podaci$Response <- as.numeric(factor(podaci$Response))
podaci$Age <- as.numeric(factor(podaci$Age))
podaci$NumberofDayEnrolled <- as.numeric(factor(podaci$NumberofDayEnrolled))
podaci$TotalSpent <- as.numeric(factor(podaci$TotalSpent))
podaci$Accepted <- as.numeric(factor(podaci$Accepted))
```
```{r}
podaci <- scale(podaci)
```

```{r}
write.csv(podaci,"nakon_1a_scale.csv", row.names = FALSE)
```
```{r}
library(clustertend)
set.seed(123)
hopkins1 <- hopkins(podaci, n = 100)
cat("Hopkins statistika za originalne podatke:", hopkins1$H, "\n")
```

```{r}
library(factoextra)
distance <- get_dist(podaci, method = "manhattan")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
distance <- get_dist(podaci, method = "euclidean")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
distance <- get_dist(podaci, method = "minkowski")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
distance <- get_dist(podaci, method = "pearson")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
```
## 1. a)

Primijeniti PAM k-medoids algoritam nad prethodno pripremljenim setom podataka (pritom obrazložiti sve korake pripreme koji su izvršeni, kao i njihov utjecaj na efikasnost PAM algoritma). Odabrati metriku distance i optimalnu vrijednost broja klastera k s kojima se dobivaju najbolje performanse i obrazložiti njihov odabir. Evaluirati dobiveni model pomoću internih mjera validacije i objasniti dobivene rezultate. Ukoliko su dobiveni rezultati zadovoljavajući, obrazložiti zašto, a u suprotnom izvršiti određena poboljšanja.

```{r}
podaci <- read.csv("nakon_1a.csv", fileEncoding = 'UTF-8')
```

```{r}
library(cluster)
model <- pam(podaci, k = 2)
plot(podaci[c("Income", "TotalSpent")], col = model$cluster)
plot(podaci[c("TotalSpent", "Kidhome")], col = model$cluster)
library(factoextra)
fviz_cluster(model, data = podaci)
```

```{r}
fviz_nbclust(podaci, pam, method = "wss")
```

```{r}
fviz_nbclust(podaci, pam, method = "silhouette")
```

```{r}
fviz_nbclust(podaci, pam, method = "gap_stat", nboot = 2)
```
#PCA analiza
```{r}
library(stats)
pca <- prcomp(podaci, scale. = TRUE)
fviz_eig(pca)
summary(pca)
```

```{r}
fviz_pca_var(pca,
 col.var = "contrib",
 gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
 repel = TRUE
 )
```

```{r}
newdata <- predict(pca, podaci)
newdata <- newdata[, 1:10]
newdata <- data.frame(newdata)
```
```{r}
set.seed(123)
hopkins1 <- hopkins(newdata, n = 100)
cat("Hopkins statistika za modifikovane podatke:", hopkins1$H, "\n")
```

```{r}
library(factoextra)
distance <- get_dist(podaci, method = "manhattan")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
distance <- get_dist(podaci, method = "euclidean")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
distance <- get_dist(podaci, method = "minkowski")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
distance <- get_dist(podaci, method = "pearson")
fviz_dist(distance, gradient = list(low = "blue", mid = "white", high =
"red"))
```
